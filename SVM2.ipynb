{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6275a82d-5685-4cff-b061-0e790547e976",
   "metadata": {},
   "source": [
    "# Real SVM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acec8966-5e2c-49c1-8fff-e198b90cc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d0589-81b1-4611-a1f7-17f11c345c8c",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "Linear Kernel:\n",
    "\n",
    "$$\\langle x, x'\\rangle$$\n",
    "\n",
    "Polynomial Kernel:\n",
    "\n",
    "$$(\\gamma \\langle x, x'\\rangle + r)^d$$\n",
    "\n",
    "Gaussian Kernel:\n",
    "$${\\displaystyle \\exp \\left(-{\\frac {\\|\\mathbf {x} -\\mathbf {x'} \\|^{2}}{2\\sigma ^{2}}}\\right)}$$\n",
    "\n",
    "Sigmoid tanh Kernel:\n",
    "\n",
    "$$\\tanh(\\gamma \\langle x,x'\\rangle + r)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1781a7-7815-40a0-a9c8-773afff6a48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9417645335842487"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(x1, x2, p = 3):\n",
    "    return (1 + np.dot(x1, x2)) ** p\n",
    "\n",
    "def gaussian_kernel(x1, x2, sigma = 5):\n",
    "    return np.exp(-np.linalg.norm(x1 - x2)** 2/(2*sigma)**2)\n",
    "\n",
    "gaussian_kernel(np.array([1,2,3]),np.array([2,3,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b42839-7abc-4bbb-9ab2-c67a08fc91f2",
   "metadata": {},
   "source": [
    "## Build SVM class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296391a-db98-4eea-b1dc-eb59823d4213",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{w} &=\\sum_{n=1}^{N} a_{n} t_{n} \\phi\\left(\\mathbf{x}_{n}\\right) \\\\\n",
    "0 &=\\sum_{n=1}^{N} a_{n} t_{n}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "y(\\mathbf{x})=\\sum_{n=1}^{N} a_{n} t_{n} k\\left(\\mathbf{x}, \\mathbf{x}_{n}\\right)+b .              (7.13)\n",
    "$$\n",
    "Having solved the quadratic programming problem and found a value for a, we \n",
    "can then determine the value of the threshold parameter b by noting that any support\n",
    "vector $x_n$ satisfies $t_ny(x_n) = 1$ . Using (7.13) this gives\n",
    "$$\n",
    "t_{n}\\left(\\sum_{m \\in \\mathcal{S}} a_{m} t_{m} k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)+b\\right)=1\n",
    "$$\n",
    "\n",
    "$$\n",
    "b=\\frac{1}{N_{\\mathcal{S}}} \\sum_{n \\in \\mathcal{S}}\\left(t_{n}-\\sum_{m \\in \\mathcal{S}} a_{m} t_{m} k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a578fb8-0bd7-4eb9-9fc4-274453ef5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self, kernel, C = None):\n",
    "        self.kernel = kernel\n",
    "        self.C = C # control soft margin\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = len(y), len(X[0])\n",
    "        \n",
    "        # P = Q(i,j) = y_i*y_j*K(x_i, x_j)\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i][j] = self.kernel(X[i],X[j])\n",
    "#         K = kernel(X,X)\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        \n",
    "        # q = -e is the vector of all ones,\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        \n",
    "        # Ax = b <=> y.Tx = 0\n",
    "        A = cvxopt.matrix(y, (1, n_samples), 'd')\n",
    "\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        \n",
    "        if self.C is None: # Gx < h <=> 0 <= alpha\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else: # Gx < h <=> 0 <= alpha <= C\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.np.diag(np.ones(n_samples))\n",
    "            G = cvxopt.matrix(np.vstack(tmp1, tmp2))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack(tmp1, tmp2))\n",
    "            \n",
    "        # Solve Quadratic Programming Problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        \n",
    "        # Lagrange multiplier\n",
    "        alpha = solution['x']\n",
    "        alpha = np.ravel(alpha)\n",
    "        sv = alpha > 1e-5 # support vectors => alpha > 0\n",
    "        sv_idx = np.arange(len(alpha))[sv]\n",
    "        self.alpha = alpha[sv_idx]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(K, sv_idx, sv)\n",
    "        print(K[sv_idx[0], sv]) \n",
    "        print(K[sv_idx[1], sv]) \n",
    "        \n",
    "        # Intercept\n",
    "        self.b = 0\n",
    "        for n in range(len(self.alpha)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.alpha * self.sv_y * K[sv_idx[n],sv])\n",
    "        self.b /= len(self.alpha)\n",
    "        \n",
    "        # This comments code also works \n",
    "#         self.b = 0      \n",
    "#         for enum1, i in enumerate(sv_idx):\n",
    "#             tmp = 0\n",
    "#             for enum2, j in enumerate(sv_idx):\n",
    "#                 tmp+= self.alpha[enum2] * self.sv_y[enum2] * K[i,j]\n",
    "#             self.b += self.sv_y[enum1] - tmp\n",
    "#         self.b /= len(sv_idx)\n",
    "        \n",
    "        # Weights vectors\n",
    "        \n",
    "        if self.kernel == linear_kernel:\n",
    "            self.w = np.zeros(n_features)\n",
    "            for a, sv_y, sv_x in zip(self.alpha, self.sv_y, self.sv):\n",
    "                self.w += a * sv_y * sv_x\n",
    "        else:\n",
    "            self.w = None # other using kernel trick to compute prediction\n",
    "        \n",
    "#         if self.kernel == linear_kernel:\n",
    "#             self.w = np.zeros(n_features)\n",
    "#             for n in range(len(self.alpha)):\n",
    "#                 self.w += self.alpha[n] * self.sv_y[n] * self.sv[n]\n",
    "#         else:\n",
    "#             self.w = None\n",
    "    def project(self, X):\n",
    "        if self.kernel == linear_kernel:\n",
    "            return np.dot(self.w, X) + self.b\n",
    "        else:\n",
    "            for i in range(len(X)):\n",
    "                predictions = np.zeros(n_features)\n",
    "                for a, sv_y, sv_x in zip(self.alpha, self.sv_y, self.sv):\n",
    "                     predictions += a * sv_y * self.kernel(X[i],sv_x)\n",
    "                predictions += self.b\n",
    "            return predictions\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.project(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d15a67ff-c48b-40d4-8949-2e585fc221d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.   7.   8.  29.  25.  30.]\n",
      " [  7.  10.  11.  39.  33.  40.]\n",
      " [  8.  11.  13.  48.  42.  50.]\n",
      " [ 29.  39.  48. 181. 161. 190.]\n",
      " [ 25.  33.  42. 161. 145. 170.]\n",
      " [ 30.  40.  50. 190. 170. 200.]] [2 4] [False False  True False  True False]\n",
      "[13. 42.]\n",
      "[ 42. 145.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[1,2],[1,3],[2,3],[9,10],[9,8],[10,10]])\n",
    "y_train = np.array([1,1,1,-1,-1,-1])\n",
    "svm = SVM(kernel=linear_kernel)\n",
    "cvxopt.solvers.options['show_progress'] = False\n",
    "cvxopt.solvers.options['maxiters']=100\n",
    "\n",
    "# print((X_train, y_train)\n",
    "SVM.fit(svm, X_train, y_train)\n",
    "svm.predict([10,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f4dc6-ce2b-4ac6-a39b-d6ee64b38133",
   "metadata": {
    "tags": []
   },
   "source": [
    "Given training vectors $x_i \\in \\mathbb{R}^p$, i=1,â€¦, n, in two classes, and a vector $y \\in \\{1, -1\\}^n$, our goal is to find $w \\in\n",
    "\\mathbb{R}^p$ and $b \\in \\mathbb{R}$ such that the prediction given by $\\text{sign} (w^T\\phi(x) + b)$ is correct for most samples.\n",
    "Solve the following primal problem:\n",
    "$$\n",
    "\\begin{align}\\begin{aligned}\\min_ {w, b, \\zeta} \\frac{1}{2} w^T w + C \\sum_{i=1}^{n} \\zeta_i\\\\\\begin{split}\\textrm {subject to } & y_i (w^T \\phi (x_i) + b) \\geq 1 - \\zeta_i,\\\\\n",
    "& \\zeta_i \\geq 0, i=1, ..., n\\end{split}\\end{aligned}\\end{align}\n",
    "$$\n",
    "\n",
    "Dual problem to the primal is:\n",
    "$$\n",
    "\\begin{align}\\begin{aligned}\\min_{\\alpha} \\frac{1}{2} \\alpha^T Q \\alpha - e^T \\alpha\\\\\\begin{split}\n",
    "\\textrm {subject to } & y^T \\alpha = 0\\\\\n",
    "& 0 \\leq \\alpha_i \\leq C, i=1, ..., n\\end{split}\\end{aligned}\\end{align}\n",
    "$$\n",
    "where, \n",
    "* $e$ is the vector of all ones,\n",
    "* $Q_{ij} \\equiv y_i y_j K(x_i, x_j)$ is an $nxn$ positive semidefine(PSD) matrix,\n",
    "* $K(x_i, x_j) = \\phi (x_i)^T \\phi (x_j)$ is the kernel,\n",
    "* $\\alpha_i$ is dual coefficients, and they are upper-bounded by $C$.\n",
    "\n",
    "`note`: $\\alpha$ is added when using Lagrange multiplier on primal problem\n",
    "        \n",
    "Once the optimization problem is solved, the output of decision_function for a given sample becomes:\n",
    "\n",
    "$$\\sum_{i\\in SV} y_i \\alpha_i K(x_i, x) + b,$$\n",
    "\n",
    "The primal problem can be equivalently formulated as:\n",
    "$$\\min_ {w, b} \\frac{1}{2} w^T w + C \\sum_{i=1}\\max(0, y_i (w^T \\phi(x_i) + b)),$$\n",
    "where we make use of **Hinge Loss**.\n",
    "\n",
    "$$\n",
    "\n",
    "Dual problem in form of Quadratic Programming:\n",
    "\\begin{align}\\begin{aligned}\\min_{\\alpha} \\frac{1}{2} x^T P x + q^T x\\\\\\begin{split}\n",
    "\\textrm {subject to } & Gx \\preceq h\\\\\n",
    "& Ax = b\\end{split}\\end{aligned}\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4d20da-0e0c-4248-a63e-d2a0c01842f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  3.  9. 14.]\n",
      " [ 3.  2.  5.  9.]\n",
      " [ 9.  5. 17. 24.]\n",
      " [14.  9. 24. 41.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[-1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.]]\n",
      "[-1.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
      "[ 0.00e+00 -1.00e+00  0.00e+00  0.00e+00]\n",
      "[ 0.00e+00  0.00e+00 -1.00e+00  0.00e+00]\n",
      "[ 0.00e+00  0.00e+00  0.00e+00 -1.00e+00]\n",
      "[ 1.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
      "[ 0.00e+00  1.00e+00  0.00e+00  0.00e+00]\n",
      "[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00]\n",
      "[ 0.00e+00  0.00e+00  0.00e+00  1.00e+00]\n",
      "\n",
      "[ 0.00e+00]\n",
      "[ 0.00e+00]\n",
      "[ 0.00e+00]\n",
      "[ 0.00e+00]\n",
      "[ 3.00e-01]\n",
      "[ 3.00e-01]\n",
      "[ 3.00e-01]\n",
      "[ 3.00e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2],[1,1],[1,4],[4,5]])\n",
    "y = np.array([-1,-1,1,1])\n",
    "n_samples, n_features = X.shape\n",
    "K = np.zeros((n_samples, n_samples))\n",
    "for i in range(n_samples):\n",
    "    for j in range(n_samples):\n",
    "        K[i,j] = linear_kernel(X[i], X[j])\n",
    "print(K)\n",
    "P = cvxopt.matrix(np.outer(y,y) * K) # y outer y * K\n",
    "q = cvxopt.matrix(np.ones(n_samples) * -1) # [-1, ..., -1]\n",
    "A = cvxopt.matrix(y, (1,n_samples)) # [y1, ..., yn]\n",
    "b = cvxopt.matrix(0.0) # 0.0\n",
    "G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1)) # np.diag(x) : make a square matrx has diag = x\n",
    "h = cvxopt.matrix(np.zeros(n_samples))\n",
    "print(np.diag(np.ones(n_samples)))\n",
    "print(np.diag(np.ones(n_samples) * -1))\n",
    "tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "tmp2 = np.identity(n_samples)\n",
    "G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "print(G)\n",
    "# print(tmp1)\n",
    "C = .3\n",
    "tmp1 = np.zeros(n_samples)\n",
    "tmp2 = np.ones(n_samples) * C\n",
    "h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df699c-2c7a-43ca-88d0-fe5d8a54c6be",
   "metadata": {},
   "source": [
    "## Refs\n",
    "\n",
    "https://gist.github.com/mblondel/586753\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#mathematical-formulation\n",
    "\n",
    "https://cvxopt.org/userguide/coneprog.html#quadratic-programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7155cb9c-c666-4582-b71d-716bef4b6ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "\n",
    "b = a > 2\n",
    "indices = np.arange(len(a))[b]\n",
    "print(indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
