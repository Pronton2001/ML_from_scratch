{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from math import pi, sqrt, exp\n",
    "from random import randrange, seed\n",
    "from csv import reader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dataset = [[3.393533211, 2.331273381, 0],\n",
    "           [3.110073483, 1.781539638, 0],\n",
    "           [1.343808831, 3.368360954, 0],\n",
    "           [3.582294042, 4.67917911, 0],\n",
    "           [2.280362439, 2.866990263, 0],\n",
    "           [7.423436942, 4.696522875, 1],\n",
    "           [5.745051997, 3.533989803, 1],\n",
    "           [9.172168622, 2.511101045, 1],\n",
    "           [7.792783481, 3.424088941, 1],\n",
    "           [7.939820817, 0.791637231, 1]]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find mean, variance, length of each attributes (columns), except for the last column (ground truth value)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def mean(X):\n",
    "    return sum(X)/ len(X)\n",
    "\n",
    "def stdev(X):\n",
    "\tmu = mean(X)\n",
    "\treturn  sum((x - mu)**2 for x in X) / (len(X) - 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "d = [[1, 3, 4],\n",
    "     [1, 2, 3],\n",
    "     [2, 3, 4],\n",
    "     [1, 2, 3]]\n",
    "print(*d)\n",
    "for column in zip(*d):\n",
    "    print(column)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 3, 4] [1, 2, 3] [2, 3, 4] [1, 2, 3]\n",
      "(1, 1, 2, 1)\n",
      "(3, 2, 3, 2)\n",
      "(4, 3, 4, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def summarize_data(dataset):\n",
    "\t# except the last column is ground truth\n",
    "\trm_last_col = [row[:-1] for row in dataset]\n",
    "\treturn [(mean(col), stdev(col), len(col)) for col in zip(*rm_last_col)]\n",
    "summarize_data(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5.178333386499999, 7.653989826170761, 10),\n",
       " (2.9984683241, 1.4848795625703213, 10)]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def separated_by_class(dataset):\n",
    "\t\"\"\"\n",
    "\tSeparate the data set into classes\n",
    "\tAssume the final colulmn is ground truth of the class\n",
    "\t\"\"\"\n",
    "\tclasses = dict()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[-1] not in classes:\n",
    "\t\t\tclasses[row[-1]] = list()\n",
    "\t\tclasses[row[-1]].append(row)\n",
    "\treturn classes\n",
    "separated_by_class(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: [[3.393533211, 2.331273381, 0],\n",
       "  [3.110073483, 1.781539638, 0],\n",
       "  [1.343808831, 3.368360954, 0],\n",
       "  [3.582294042, 4.67917911, 0],\n",
       "  [2.280362439, 2.866990263, 0]],\n",
       " 1: [[7.423436942, 4.696522875, 1],\n",
       "  [5.745051997, 3.533989803, 1],\n",
       "  [9.172168622, 2.511101045, 1],\n",
       "  [7.792783481, 3.424088941, 1],\n",
       "  [7.939820817, 0.791637231, 1]]}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def summarize_by_class(dataset):\n",
    "\tseparated = separated_by_class(dataset)\n",
    "\tsumaries = dict()\n",
    "\tfor class_val, rows_class_val in separated.items(): # items() means (keys, values)\n",
    "\t\tsumaries[class_val] = summarize_data(rows_class_val)\n",
    "\treturn sumaries\n",
    "print(summarize_by_class(dataset))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: [(2.7420144012, 0.8585288681757653, 5), (3.0054686692, 1.2261788197598094, 5)], 1: [(7.6146523718, 1.5238227453753934, 5), (2.9914679790000003, 2.1146776839446155, 5)]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Probability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def gauss(x, mean, stdev):\n",
    "    assert stdev !=0\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return 1 / (sqrt(2 * pi) * stdev ) * exponent\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class Probabilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def MAP(dataset, input_row):\n",
    "    \"\"\"\n",
    "    Maximum a Posteriori (MAP) \n",
    "    h = argmax_h P(h|D) = argmax_h P(D|h) * P(h)\n",
    "    P(D|h) = P(D1|h) * P(D2|h) * ... * P(Dn|h)\n",
    "    \n",
    "    where, \n",
    "        D: real data\n",
    "        h: a hypothesis, in classification, a class\n",
    "        P(D|h) : Likelihood distribution of Data given a specific hypothesis, in classification,\n",
    "            a specific probability distribution and its parameters\n",
    "        P(h): Prior distribution\n",
    "        P(h|D): Most likely hypothesis given data, in classification, Most likely class given data\n",
    "    \"\"\"\n",
    "    total_rows = len(dataset)\n",
    "    summaries = summarize_by_class(dataset)\n",
    "    prob = dict()\n",
    "    max_prob, retClass = 0.0, None\n",
    "    for class_val, class_summaries in summaries.items():\n",
    "        prob[class_val] = class_summaries[0][2] / float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            prob[class_val] *= gauss(input_row[i], mean, stdev)\n",
    "        if max_prob < prob[class_val]:\n",
    "            retClass = class_val\n",
    "            max_prob = prob[class_val]\n",
    "    return retClass, prob\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train_set, test_set):\n",
    "    preidictions = list()\n",
    "    for row in test_set:\n",
    "        preidictions.append(MAP(train_set,row)[0])\n",
    "        # print(MAP(train_set,row))\n",
    "    return preidictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Work with Real Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, \"rt\")\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])  # concatenate lists of lists to a list\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            # test_set use to predict => no need to hold [class] data\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'data/BankNote_Authentication.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# remove the string [attributes]\n",
    "dataset.pop(0)\n",
    "for i in range(len(dataset[0])-1): # except for the last column\n",
    "\tstr_column_to_float(dataset, i)\n",
    "\n",
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "\n",
    "# predict the label\n",
    "n_folds = 5\n",
    "\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [59.48905109489051, 62.40875912408759, 63.503649635036496, 75.91240875912408, 60.58394160583942]\n",
      "Mean Accuracy: 64.380%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This model cannot work with huge attributes, i.e `data/sonar.csv` due to the multiplication increase when # of attributes increase. The probability of each class rapidly converges to zero and we cannot use it to the the Maximum a Posteriori (MAP).\n",
    "\n",
    "I tried to print the probability of these classes:\n",
    "\n",
    "2.9139230184726384e-13\n",
    "\n",
    "1.0403767988304062e-181\n",
    "\n",
    "0.0\n",
    "\n",
    "0.0\n",
    "\n",
    "..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Refs\n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mp_env': venv)"
  },
  "interpreter": {
   "hash": "28f96ec01d3331ab2b5d4a1bb32d02e762004829634cea2cd2eeaefdb8bb653c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}