{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generative Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes classification\n",
    "\n",
    "Asumption:\n",
    "\n",
    "- h ~ Bernoulli(phi)\n",
    "- D|h ~ Bernoulli(D)\n",
    "- Input data is conditional independent given y, i.e $p(D_i|D_j,y) = p(D_i|y)\\forall i,j$ \n",
    "\n",
    "With continous features problem, we can discretize a continous feature into ***k*** bounded ranges and then count them to find:\n",
    "\n",
    "$P(D_i=d_{ir}| h = 0)$ and $P(D_i=d_{ir}| h = 1) \\forall r \\in k=\\{<2,>=2 \\&<5,...\\}$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "source": [
    "from math import pi, sqrt, exp, log, inf\n",
    "from random import randrange, seed\n",
    "from csv import reader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "source": [
    "dataset = [[3.393533211, 2.331273381, 0],\n",
    "           [3.110073483, 1.781539638, 0],\n",
    "           [1.343808831, 3.368360954, 0],\n",
    "           [3.582294042, 4.67917911, 0],\n",
    "           [2.280362439, 2.866990263, 0],\n",
    "           [7.423436942, 4.696522875, 1],\n",
    "           [5.745051997, 3.533989803, 1],\n",
    "           [9.172168622, 2.511101045, 1],\n",
    "           [7.792783481, 3.424088941, 1],\n",
    "           [7.939820817, 0.791637231, 1]]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find mean, variance, length of each attributes (columns), except for the last column (ground truth value)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "source": [
    "def mean(X):\n",
    "    return sum(X)/ len(X)\n",
    "\n",
    "def stdev(X):\n",
    "\tmu = mean(X)\n",
    "\treturn  sum((x - mu)**2 for x in X) / (len(X) - 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "source": [
    "d = [[1, 3, 4],\n",
    "     [1, 2, 3],\n",
    "     [2, 3, 4],\n",
    "     [1, 2, 3]]\n",
    "print(*d)\n",
    "for column in zip(*d):\n",
    "    print(column)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 3, 4] [1, 2, 3] [2, 3, 4] [1, 2, 3]\n",
      "(1, 1, 2, 1)\n",
      "(3, 2, 3, 2)\n",
      "(4, 3, 4, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "source": [
    "def summarize_data(dataset):\n",
    "\t# except the last column is ground truth\n",
    "\trm_last_col = [row[:-1] for row in dataset]\n",
    "\treturn [(mean(col), stdev(col), len(col)) for col in zip(*rm_last_col)]\n",
    "summarize_data(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5.178333386499999, 7.653989826170761, 10),\n",
       " (2.9984683241, 1.4848795625703213, 10)]"
      ]
     },
     "metadata": {},
     "execution_count": 411
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "source": [
    "def separated_by_class(dataset):\n",
    "\t\"\"\"\n",
    "\tSeparate the data set into classes\n",
    "\tAssume the final colulmn is ground truth of the class\n",
    "\t\"\"\"\n",
    "\tclasses = dict()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[-1] not in classes:\n",
    "\t\t\tclasses[row[-1]] = list()\n",
    "\t\tclasses[row[-1]].append(row)\n",
    "\treturn classes\n",
    "separated_by_class(dataset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: [[3.393533211, 2.331273381, 0],\n",
       "  [3.110073483, 1.781539638, 0],\n",
       "  [1.343808831, 3.368360954, 0],\n",
       "  [3.582294042, 4.67917911, 0],\n",
       "  [2.280362439, 2.866990263, 0]],\n",
       " 1: [[7.423436942, 4.696522875, 1],\n",
       "  [5.745051997, 3.533989803, 1],\n",
       "  [9.172168622, 2.511101045, 1],\n",
       "  [7.792783481, 3.424088941, 1],\n",
       "  [7.939820817, 0.791637231, 1]]}"
      ]
     },
     "metadata": {},
     "execution_count": 412
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "source": [
    "def summarize_by_class(dataset):\n",
    "\tseparated = separated_by_class(dataset)\n",
    "\tsumaries = dict()\n",
    "\tfor class_val, rows_class_val in separated.items(): # items() means (keys, values)\n",
    "\t\tsumaries[class_val] = summarize_data(rows_class_val)\n",
    "\treturn sumaries\n",
    "print(summarize_by_class(dataset))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: [(2.7420144012, 0.8585288681757653, 5), (3.0054686692, 1.2261788197598094, 5)], 1: [(7.6146523718, 1.5238227453753934, 5), (2.9914679790000003, 2.1146776839446155, 5)]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Probability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "source": [
    "def gauss(x, mean, stdev):\n",
    "    assert stdev !=0\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return 1 / (sqrt(2 * pi) * stdev ) * exponent\n",
    "\n",
    "def log_gausian(x, mean, stdev):\n",
    "    return - log(stdev) - 0.5 * (x-mean)**2/stdev**2 # removed constant: -0.5 * log(2*pi)\n",
    "\n",
    "def pro_smooth(Nh, N, p):\n",
    "    \"\"\"\n",
    "    Smooth technique\n",
    "    prob(X) = (Nh+mp) / (N + m)\n",
    "\n",
    "    where, \n",
    "        Nh: # occurences of the type A in class h\n",
    "        N: # of total types in class h\n",
    "        m: equivalent sample size (heuristic choice)\n",
    "        p: probability of the type A\n",
    "    \"\"\"\n",
    "    m = 3 \n",
    "    return (Nh+m*p)/(N + m)\n",
    "# log(gauss(0.014400, 0.022630, 0.000188)) will get zero. \n",
    "# Instead, we use log_gaussian that we computed by hand first.\n",
    "log_gausian(0.014400, 0.022630, 0.000188)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-949.6160989014708"
      ]
     },
     "metadata": {},
     "execution_count": 414
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class Probabilities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "source": [
    "def MAP(dataset, input_row):\n",
    "    \"\"\"\n",
    "    Maximum a Posteriori (MAP) \n",
    "    h = argmax_h P(h|D) = argmax_h P(D|h) * P(h)\n",
    "    P(D|h) = P(D1|h) * P(D2|h) * ... * P(Dn|h), assuming that these D1,D2,... is conditional independent\n",
    "    \n",
    "    where, \n",
    "        D: set of attributes/data/columns that contains {D1, D2,...}\n",
    "        h: a hypothesis, in classification, a class\n",
    "        P(D|h) : Likelihood distribution of data given a specific hypothesis, in classification,\n",
    "            likelihood distribution of data given a specific class\n",
    "        P(h): Prior distribution\n",
    "        P(h|D): Most likely hypothesis given data, in classification, most likely class given data\n",
    "    \"\"\"\n",
    "    total_rows = len(dataset)\n",
    "    summaries = summarize_by_class(dataset)\n",
    "    prob = dict()\n",
    "    max_prob, retClass = -inf, None\n",
    "    for class_val, class_summaries in summaries.items():\n",
    "        prob[class_val] = log(class_summaries[0][2] / float(total_rows))\n",
    "\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            prob[class_val] += log_gausian(input_row[i], mean, stdev)\n",
    "        if max_prob < prob[class_val]:\n",
    "            retClass = class_val\n",
    "            max_prob = prob[class_val]\n",
    "    return retClass, prob\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train_set, test_set):\n",
    "    preidictions = list()\n",
    "    for row in test_set:\n",
    "        preidictions.append(MAP(train_set,row)[0])\n",
    "        # print(MAP(train_set,row))\n",
    "    return preidictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Work with Real Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, \"rt\")\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column])\n",
    "        \n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])  # concatenate lists of lists to a list\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            # test_set use to predict => no need to hold [class] data\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gaussian Discriminnat Analaysis\n",
    "\n",
    "Assumption:\n",
    "\n",
    "- y ~ Bernoulli($\\phi$) - 1 dimension\n",
    "- x|y ~ Gaussian($\\mu, \\Sigma$) - d dimension"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "source": [
    "seed(1)\n",
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'data/sonar.csv'\n",
    "filename = 'data/BankNote_Authentication.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# remove the string [attributes]\n",
    "dataset.pop(0)\n",
    "\n",
    "for i in range(len(dataset[0])-1): # except for the last column\n",
    "\tstr_column_to_float(dataset, i)\n",
    "\n",
    "# fit model\n",
    "model = summarize_by_class(dataset)\n",
    "\n",
    "# predict the label\n",
    "n_folds = 5\n",
    "\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [62.40875912408759, 63.868613138686136, 59.48905109489051, 66.42335766423358, 64.96350364963503]\n",
      "Mean Accuracy: 63.431%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This model cannot work with huge attributes, i.e `data/sonar.csv` due to the multiplication increase when # of attributes increase. The probability of each class rapidly converges to zero and we cannot use it to the the Maximum a Posteriori (MAP).\n",
    "\n",
    "I tried to print the probability of these classes:\n",
    "\n",
    "2.9139230184726384e-13\n",
    "\n",
    "1.0403767988304062e-181\n",
    "\n",
    "0.0\n",
    "\n",
    "0.0\n",
    "\n",
    "...\n",
    "\n",
    "Problem: numercal unstability\n",
    "\n",
    "Attemp: use log to avoid the numerical problem\n",
    "\n",
    "```python\n",
    "# prob[class_val] = (class_summaries[0][2] / float(total_rows))\n",
    "prob[class_val] = log(class_summaries[0][2] / float(total_rows)\n",
    "... \n",
    "# prob[class_val] *= (gauss(input_row[i], mean, stdev))\n",
    "prob[class_val] += log_gausian(input_row[i], mean, stdev)\n",
    "```\n",
    "\n",
    "However, the average accuracy of this model on the `data\\sonar.csv` dataset is just over 50% that is the same as the guessing.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "source": [
    "X = np.array([[1,2,3,1],[1,2,2,1],[0,1,4,0]], np.float32)\n",
    "y = np.array([x[-1] for x in X])\n",
    "# print(X.shape, y.shape)\n",
    "mean = [X[y==k].mean(axis = 0) for k in [0,1]]\n",
    "mean"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0., 1., 4., 0.], dtype=float32),\n",
       " array([1. , 2. , 2.5, 1. ], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 418
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "source": [
    "X_u = X.copy()\n",
    "\n",
    "for k in [0,1]: X_u[y==k] -= mean[k]\n",
    "stddev = X_u.T.dot(X_u) / len(y)\n",
    "invStddev = np.linalg.pinv(stddev)\n",
    "invStddev\n",
    "len(mean)\n",
    "# mean[1]\n",
    "# X_u[y==1] -= mean[1]\n",
    "X = [x[:-1] for x in X]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "source": [
    "def fit(X, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X: A list with (n x d); n datasize & [d] value (features)\n",
    "        y: A list with (n x 1); n datasize & 1 value (label)\n",
    "    Return:\n",
    "        mean: (2 x d) (2 because we have 2 classes)\n",
    "        covariance: (d x d) = 1/n * SUM\n",
    "        fi: scalar (because we have 2 classes, fi = P(y = 1) = 1 - P(y = 0))\n",
    "    \"\"\"\n",
    "    mean = np.array([X[y == k].mean(axis=0) for k in [0, 1]])\n",
    "    X_u = X.copy()  # X_u: (n x d)\n",
    "    for k in [0, 1]:\n",
    "        X_u[y == k] -= mean[k]\n",
    "        \n",
    "    covariance = X_u.T.dot(X_u) / len(y) # X_u.T(d x n) * X_u(n x d) / n    -> (dxd)\n",
    "    fi = y.mean()\n",
    "    return mean, covariance, fi\n",
    "\n",
    "\n",
    "def predict(X, u, invE, fi):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            X: (n x d)\n",
    "            u: (2 x d)\n",
    "            invE: (d x d)\n",
    "            fi: scalar\n",
    "        Return:\n",
    "            Array of [n] predictions\n",
    "    \"\"\"\n",
    "    return np.argmax([compute_prob(X, u[c], invE, fi, c) for c in [0, 1]], axis=0)\n",
    "\n",
    "\n",
    "def compute_prob(X, u, invE, fi, c):\n",
    "    \"\"\"\n",
    "    X: dataset, the last column is the ground truth\n",
    "    c: class\n",
    "\n",
    "    Return: P(X,c) = P(X|c)P(c)\n",
    "        where,\n",
    "        P(X|c) ~ Gaussian(u, E)\n",
    "        P(c) ~ Berounlli(phi)\n",
    "    \"\"\"\n",
    "    phi = fi**c * (1-fi)**(1-c)\n",
    "    # return np.exp(-1.0 * np.sum((X - u).dot(invE)*(X - u), axis=1)) * phi    # sum up the row/features\n",
    "    return -1.0* np.sum((X-u).dot(invE)*(X-u),axis=1) + log(phi) # sum up the row/features\n",
    "\n",
    "\n",
    "def Binary_GDA(train_set, test_set):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train_set: (n x (d+1)), with [d] features and 1 label column\n",
    "        test_set: (n x (d+1)), with [d] features and 1 label column\n",
    "    Return:\n",
    "        A list of predictions: (1 x n)\n",
    "    \"\"\" \n",
    "    y = np.array([x[-1] for x in train_set])\n",
    "    X = np.array([x[:-1] for x in train_set])\n",
    "    test_set = np.array([x[:-1] for x in test_set])\n",
    "\n",
    "    u, E, fi = fit(X, y)\n",
    "    invE = np.linalg.pinv(E)\n",
    "    return predict(test_set, u, invE, fi)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "source": [
    "X = np.array([[1, 2, 3, 1, 1],\n",
    "              [1, 2, 2, 3, 1],\n",
    "              [0, 1, 4, 1, 0],\n",
    "              [1, 1, 1, 3, 1],\n",
    "              [1, 2, 3, 4, 0]], np.float32)\n",
    "\n",
    "y = np.array([x[-1] for x in X])\n",
    "X = np.array([x[:-1] for x in X])\n",
    "\n",
    "u, E, fi = fit(X, y)\n",
    "invE = np.linalg.pinv(E)\n",
    "phi0 = 1 - fi\n",
    "phi1 = fi\n",
    "\n",
    "# why element-wise product\n",
    "L0 = np.exp(-1.0 * np.sum((X - u[0]).dot(invE)*(X-u[0]),axis=1) ) * phi0\n",
    "# why element-wise product\n",
    "L1 = np.exp(-1.0 * np.sum((X - u[1]).dot(invE)*(X-u[1]), axis=1) ) * phi1\n",
    "\n",
    "print(np.argmax([L0, L1], axis=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 0 1 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "source": [
    "seed(1)\n",
    "# Make a prediction with Naive Bayes on Iris Dataset\n",
    "filename = 'data/BankNote_Authentication.csv'\n",
    "filename = 'data/sonar.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# remove the string [attributes]\n",
    "dataset.pop(0)\n",
    "\n",
    "for i in range(len(dataset[0])-1): # except for the last column\n",
    "\tstr_column_to_float(dataset, i)\n",
    "\n",
    "# Check if the last row is not INT{0,1}\n",
    "if not isinstance(dataset[0][-1], int):\n",
    "\tprint(\"The last row convert from str to int\")\n",
    "\tstr_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "# predict the label\n",
    "n_folds = 5\n",
    "\n",
    "scores = evaluate_algorithm(dataset, Binary_GDA, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The last row convert from str to int\n",
      "Scores: [68.29268292682927, 75.60975609756098, 75.60975609756098, 75.60975609756098, 65.85365853658537]\n",
      "Mean Accuracy: 72.195%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "I updated Binary_GDA(linear) and it's accuracy is increase to same as decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Refs\n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mp_env': venv)"
  },
  "interpreter": {
   "hash": "28f96ec01d3331ab2b5d4a1bb32d02e762004829634cea2cd2eeaefdb8bb653c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}